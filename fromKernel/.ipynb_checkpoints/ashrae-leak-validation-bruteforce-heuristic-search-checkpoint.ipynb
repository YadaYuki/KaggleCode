{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "Original Kernel: https://www.kaggle.com/yamsam/ashrae-leak-validation-and-more/notebook#Leak-Validation-for-public-kernels(not-used-leak-data)\n",
    "\n",
    "Additions: Added a search method to find combination of weights with best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All we need is Leak Validation(LV) ?\n",
    "\n",
    "* **if you like this kernel, please upvote original kernels.**\n",
    "* update site-4 and site-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this kernel is still work in progress, but i hope you can find something usefull from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "root = Path('../input/ashrae-feather-format-for-fast-loading')\n",
    "\n",
    "train_df = pd.read_feather(root/'train.feather')\n",
    "test_df = pd.read_feather(root/'test.feather')\n",
    "#weather_train_df = pd.read_feather(root/'weather_train.feather')\n",
    "#weather_test_df = pd.read_feather(root/'weather_test.feather')\n",
    "building_meta_df = pd.read_feather(root/'building_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'm now using my leak data station kernel to shortcut.\n",
    "leak_df = pd.read_feather('../input/ashrae-leak-data-station/leak.feather')\n",
    "\n",
    "leak_df.fillna(0, inplace=True)\n",
    "leak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\n",
    "leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 # remove large negative values\n",
    "leak_df = leak_df[leak_df.building_id!=245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df.meter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (leak_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(leak_df) / len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Validation for public kernels(not used leak data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission1 = pd.read_csv('../input/ashrae-kfold-lightgbm-without-leak-1-08/submission.csv', index_col=0)\n",
    "sample_submission2 = pd.read_csv('../input/ashrae-half-and-half/submission.csv', index_col=0)\n",
    "sample_submission3 = pd.read_csv('../input/ashrae-highway-kernel-route4/submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred1'] = sample_submission1.meter_reading\n",
    "test_df['pred2'] = sample_submission2.meter_reading\n",
    "test_df['pred3'] = sample_submission3.meter_reading\n",
    "\n",
    "test_df.loc[test_df.pred3<0, 'pred3'] = 0 \n",
    "\n",
    "del  sample_submission1,  sample_submission2,  sample_submission3\n",
    "gc.collect()\n",
    "\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "leak_df = reduce_mem_usage(leak_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df = leak_df.merge(test_df[['building_id', 'meter', 'timestamp', 'pred1', 'pred2', 'pred3', 'row_id']], left_on = ['building_id', 'meter', 'timestamp'], right_on = ['building_id', 'meter', 'timestamp'], how = \"left\")\n",
    "leak_df = leak_df.merge(building_meta_df[['building_id', 'site_id']], on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df['pred1_l1p'] = np.log1p(leak_df.pred1)\n",
    "leak_df['pred2_l1p'] = np.log1p(leak_df.pred2)\n",
    "leak_df['pred3_l1p'] = np.log1p(leak_df.pred3)\n",
    "leak_df['meter_reading_l1p'] = np.log1p(leak_df.meter_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df[leak_df.pred1_l1p.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ashrae-kfold-lightgbm-without-leak-1-08\n",
    "sns.distplot(leak_df.pred1_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred1_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score1=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ashrae-half-and-half\n",
    "sns.distplot(leak_df.pred2_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred2_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score2=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meter split based\n",
    "sns.distplot(leak_df.pred3_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred3_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score3=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ashrae-kfold-lightgbm-without-leak-1-08 looks best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Validation for Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one idea how we can use LV usefull is blending. We probably can find best blending method without LB probing and it's means we can save our submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df['mean_pred'] = np.mean(leak_df[['pred1', 'pred2', 'pred3']].values, axis=1)\n",
    "leak_df['mean_pred_l1p'] = np.log1p(leak_df.mean_pred)\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.mean_pred_l1p, leak_df.meter_reading_l1p))\n",
    "\n",
    "\n",
    "sns.distplot(leak_df.mean_pred_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "print ('mean score=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df['median_pred'] = np.median(leak_df[['pred1', 'pred2', 'pred3']].values, axis=1)\n",
    "leak_df['median_pred_l1p'] = np.log1p(leak_df.median_pred)\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.median_pred_l1p, leak_df.meter_reading_l1p))\n",
    "\n",
    "sns.distplot(leak_df.median_pred_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "print ('meadian score=', leak_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ummm... it looks mean blending is beter than median blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "scores = np.zeros(N,)\n",
    "for i in range(N):\n",
    "    p = i * 1./N\n",
    "    v = p * leak_df['pred1'].values + (1.-p) * leak_df ['pred3'].values\n",
    "    vl1p = np.log1p(v)\n",
    "    scores[i] = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weight = np.argmin(scores) *  1./N\n",
    "print (scores.min(), best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and more\n",
    "scores = np.zeros(N,)\n",
    "for i in range(N):\n",
    "    p = i * 1./N\n",
    "    v =  p * (best_weight * leak_df['pred1'].values + (1.-best_weight) * leak_df ['pred3'].values) + (1.-p) * leak_df ['pred2'].values\n",
    "    vl1p = np.log1p(v)\n",
    "    scores[i] = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weight2 = np.argmin(scores) *  1./N\n",
    "print (scores.min(), best_weight2)\n",
    "# its seams better than simple mean 0.92079717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.33 0.33 0.3 0.9859179\n",
    "0.33 0.33 0.33 \n",
    "0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Possible Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = list(np.linspace(0.2,0.5,11))\n",
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of All Possible Combinations of Three Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [all_combinations, all_combinations, all_combinations]\n",
    "# remember to do the reverse!\n",
    "all_l = list(itertools.product(*l)) + list(itertools.product(*reversed(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Combinations to Have Those With Sum of Weights > 0.95 \n",
    "\n",
    "Reason being weight sum of 0.96 led to LB score of 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_combis = [l for l in all_l if l[0] + l[1] + l[2] > 0.92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_combis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin the Search For Combination With Lowest Score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combi = [] # of the form (i, score)\n",
    "for i, combi in enumerate(filtered_combis):\n",
    "    print(\"Now at: \" + str(i) + \" out of \" + str(len(filtered_combis)))\n",
    "    score1 = combi[0]\n",
    "    score2 = combi[1]\n",
    "    score3 = combi[2]\n",
    "    v = score1 * leak_df['pred1'].values + score2 * leak_df['pred3'].values + score3 * leak_df['pred2'].values\n",
    "    vl1p = np.log1p(v)\n",
    "    curr_score = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))\n",
    "    \n",
    "    if best_combi:\n",
    "        prev_score = best_combi[0][1]\n",
    "        if curr_score < prev_score:\n",
    "            best_combi[:] = []\n",
    "            best_combi += [(i, curr_score)]\n",
    "    else:\n",
    "        best_combi += [(i, curr_score)]\n",
    "            \n",
    "score = best_combi[0][1]\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\n",
    "\n",
    "# extract best combination\n",
    "final_combi = filtered_combis[best_combi[0][0]]\n",
    "w1 = final_combi[0]\n",
    "w2 = final_combi[1]\n",
    "w3 = final_combi[2]\n",
    "print(\"The weights are: w1=\" + str(w1) + \", w2=\" + str(w2) + \", w3=\" + str(w3))\n",
    "\n",
    "sample_submission['meter_reading'] = w1 * test_df.pred1 +  w2 * test_df.pred3  + w3 * test_df.pred2\n",
    "sample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(sample_submission.meter_reading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df = leak_df[['meter_reading', 'row_id']].set_index('row_id').dropna()\n",
    "sample_submission.loc[leak_df.index, 'meter_reading'] = leak_df['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(sample_submission.meter_reading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "- Increase the range of weights\n",
    "- Vary tolerance for sum of weights (currently tol = 0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
